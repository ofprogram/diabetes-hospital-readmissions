{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from scipy import interp\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.metrics import Precision, Recall\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from datetime import datetime, timedelta\n",
    "from pandas.plotting import scatter_matrix\n",
    "from statsmodels.tools import add_constant\n",
    "from statsmodels.discrete.discrete_model import Logit\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "# from sklearn.ensemble.partial_dependence import plot_partial_dependence\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, train_test_split, GridSearchCV, KFold\n",
    "from sklearn.metrics import mean_squared_error, r2_score, accuracy_score, confusion_matrix\n",
    "from sklearn.metrics import precision_score, recall_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import data\n",
    "\n",
    "def load():\n",
    "    data = pd.read_csv(r'data/diabetic_data.csv')\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pick the features of interest. \n",
    "\n",
    "def clean(data):\n",
    "    df = data[['race', 'gender', 'age', 'admission_type_id', 'discharge_disposition_id',\n",
    "        'admission_source_id', 'time_in_hospital', 'num_lab_procedures', 'num_procedures',\n",
    "        'num_medications', 'number_outpatient', 'number_emergency',\n",
    "        'number_inpatient', 'number_diagnoses', 'A1Cresult', 'change', 'diabetesMed',\n",
    "        'metformin', 'repaglinide', 'nateglinide', 'chlorpropamide',\n",
    "        'glimepiride', 'acetohexamide', 'glipizide', 'glyburide', 'tolbutamide',\n",
    "        'pioglitazone', 'rosiglitazone', 'acarbose', 'miglitol', 'troglitazone',\n",
    "        'tolazamide', 'insulin', 'glyburide-metformin', 'glipizide-metformin',\n",
    "        'glimepiride-pioglitazone', 'metformin-rosiglitazone', 'metformin-pioglitazone']]\n",
    "\n",
    "    #Change 'unknown' to 'other'\n",
    "\n",
    "    df['race'] = df['race'].replace(['?'],'Other')\n",
    "\n",
    "    #Define target variable. \n",
    "\n",
    "    data['readmitted'] = [ 0 if val == 'NO' else 1 for val in data['readmitted']]\n",
    "    \n",
    "    return df, data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set X, y, and get dummy variables.\n",
    "\n",
    "def get_dummies(df, data):\n",
    "\n",
    "    X = pd.get_dummies(df, columns=['race', 'gender', 'age', 'admission_type_id', \n",
    "        'discharge_disposition_id', 'admission_source_id', 'A1Cresult', 'change', \n",
    "        'diabetesMed', 'metformin', 'repaglinide', 'nateglinide', 'chlorpropamide',\n",
    "        'glimepiride', 'acetohexamide', 'glipizide', 'glyburide', 'tolbutamide',\n",
    "        'pioglitazone', 'rosiglitazone', 'acarbose', 'miglitol', 'troglitazone',\n",
    "        'tolazamide', 'insulin', 'glyburide-metformin', 'glipizide-metformin',\n",
    "        'glimepiride-pioglitazone', 'metformin-rosiglitazone', 'metformin-pioglitazone'])\n",
    "\n",
    "    y = data['readmitted']\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pie charts\n",
    "\n",
    "df.race.value_counts().plot(kind='pie', figsize=(12,12), title='Race', fontsize=(15), style='fivethirtyeight')\n",
    "df.gender.value_counts().plot(kind='pie', figsize=(12,12), title='Gender', fontsize=(15), style='fivethirtyeight')\n",
    "df.age.value_counts().plot(kind='pie', figsize=(12,12), title='Age', fontsize=(15), style='fivethirtyeight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bar Graphs\n",
    "\n",
    "ave_meds = df[['age', 'num_medications']].groupby('age').mean().sort_values(by='age')\n",
    "ave_procedures = df[['age', 'num_procedures']].groupby('age').mean().sort_values(by='age')\n",
    "ave_lab_procedures = df[['age', 'num_lab_procedures']].groupby('age').mean().sort_values(by='age')\n",
    "ave_time_spent = df[['age', 'time_in_hospital']].groupby('age').mean().sort_values(by='age')\n",
    "\n",
    "ave_meds.num_medications.plot(kind='bar', title=' Average Number of Medications', figsize=(12,9), fontsize=(15), style='fivethirtyeight')\n",
    "ave_lab_procedures.num_lab_procedures.plot(kind='bar', title='Average Number of Lab Procedures', figsize=(12,9), fontsize=(15), style='fivethirtyeight')\n",
    "ave_procedures.num_procedures.plot(kind='bar', title='Average Number of Procedures', figsize=(12,9), fontsize=(15), style='fivethirtyeight')\n",
    "ave_time_spent.time_in_hospital.plot(kind='bar', title='Average Time in Hospital', figsize=(12,9), fontsize=(15), style='fivethirtyeight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train-test split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Base ML Models\n",
    "\n",
    "lr = LogisticRegression()\n",
    "rf = RandomForestClassifier()\n",
    "gdbc = GradientBoostingClassifier()\n",
    "\n",
    "#Optimized ML Models\n",
    "\n",
    "lr_1 = LogisticRegression(penalty='l2', tol=0.0001, C=0.01, fit_intercept=True, intercept_scaling=1.0)\n",
    "rf_1= RandomForestClassifier(bootstrap=False, max_depth=None, max_features='sqrt', min_samples_leaf=2, min_samples_split=2, n_estimators=80, random_state=1)\n",
    "gdbc_1 = GradientBoostingClassifier(learning_rate=0.50, n_estimators=120, random_state=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Classification Report\n",
    "\n",
    "def class_report(model):\n",
    "    model.fit(X_train, y_train)\n",
    "    prediction = model.predict(X_test)\n",
    "    return classification_report(y_test, prediction)\n",
    "  \n",
    "#Base models\n",
    "\n",
    "print(class_report(lr))\n",
    "print(class_report(rf))\n",
    "print(class_report(gdbc))\n",
    "\n",
    "#Optimized models\n",
    "\n",
    "print(class_report(lr_1))\n",
    "print(class_report(rf_1))\n",
    "print(class_report(gdbc_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Feature importance graphs\n",
    "\n",
    "def feat_importance(model): \n",
    "    model.fit(X_train, y_train)\n",
    "    feat_scores = pd.DataFrame({'Fraction of Samples Affected' : model.feature_importances_}, index=X.columns)\n",
    "    feat_scores = feat_scores.sort_values(by='Fraction of Samples Affected')\n",
    "    return feat_scores[135:].plot(kind='barh', title='Most Important Features', figsize=(12,9), fontsize=(15), style='fivethirtyeight')\n",
    "\n",
    "print(feat_importance(rf))\n",
    "print(feat_importance(gdbc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Neural Network\n",
    "\n",
    "def basic_net(X_train, y_train):    \n",
    "    n_feats = X_train.shape[1]\n",
    "\n",
    "    model = Sequential() # sequence of layers\n",
    "\n",
    "    hidden_units = 155\n",
    "    n_classes = 2\n",
    "\n",
    "    input_layer = Dense(units=hidden_units,\n",
    "                    input_dim=n_feats,\n",
    "                    kernel_initializer='constant',\n",
    "                    activation='relu')\n",
    "\n",
    "    hidden_layer = Dense(units=n_units,\n",
    "                    kernel_initializer='constant',\n",
    "                    activation='relu')\n",
    "\n",
    "    output_layer = Dense(units=n_classes,\n",
    "                    input_dim=hidden_units,\n",
    "                    kernel_initializer='uniform',\n",
    "                    activation='sigmoid')\n",
    "    model.add(input_layer)\n",
    "    model.add(hidden_layer)\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', optimizer=\"adam\", metrics=[\"f1score\"])\n",
    "    \n",
    "    return model.fit(X_train[:100], to_categorical(y_train), epochs=10, batch=32)\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest Trees Vs. Accuracy Graph\n",
    "\n",
    "def rf_chart(model):\n",
    "    num_trees = range(5, 100, 5)\n",
    "    accuracies = []\n",
    "    for n in num_trees:\n",
    "        tot = 0\n",
    "        for i in range(5):\n",
    "            model.fit(X_train, y_train)\n",
    "            tot += rf.score(X_test, y_test)\n",
    "        accuracies.append(tot / 5)\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(num_trees, accuracies)\n",
    "    ax.set_xlabel(\"Number of Trees\")\n",
    "    ax.set_ylabel(\"Accuracy\")\n",
    "    ax.set_title('Accuracy vs Num Trees')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grid Search Random Forest\n",
    "\n",
    "def grid_search_rf(X_train, y_train):\n",
    "    random_forest_grid = {'max_depth': [25, 50, None],\n",
    "                      'max_features': ['sqrt', 'log2', None],\n",
    "                      'min_samples_split': [2, 4],\n",
    "                      'min_samples_leaf': [1, 2, 4],\n",
    "                      'bootstrap': [True, False],\n",
    "                      'n_estimators': [10, 20, 40, 80, 100],\n",
    "                      'random_state': [1]}\n",
    "\n",
    "    rf_gridsearch = GridSearchCV(RandomForestClassifier(),\n",
    "                             random_forest_grid,\n",
    "                             n_jobs=-1,\n",
    "                             verbose=True,\n",
    "                             scoring='f1')\n",
    "\n",
    "    rf_gridsearch.fit(X_train, y_train)\n",
    "\n",
    "print(\"best parameters:\", rf_gridsearch.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grid Search Gradient Boost\n",
    "\n",
    "def grid_search_gdbc(X_train, y_train):\n",
    "    gradient_boost_grid = {'max_depth': [2, 4, 6, None],\n",
    "                          'max_features': ['sqrt', 'log2', None],\n",
    "                          'min_samples_split': [2, 4],\n",
    "                          'min_samples_leaf': [1, 2, 4],\n",
    "                          'n_estimators': [10, 20, 80, 100, 120],\n",
    "                          'random_state': [1],\n",
    "                          'learning_rate': [0.01, .1, .5, 1],\n",
    "                          'subsample': [.25, .5, .75, 1]}\n",
    "\n",
    "\n",
    "    gb_gridsearch = GridSearchCV(GradientBoostingClassifier(),\n",
    "                                 gradient_boost_grid,\n",
    "                                 n_jobs=-1,\n",
    "                                 verbose=True,\n",
    "                                 scoring='f1')\n",
    "    gb_gridsearch.fit(X_train, y_train)\n",
    "\n",
    "print(\"best parameters:\", gb_gridsearch.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ROC Curves\n",
    "\n",
    "def plot_roc(X, y, clf_class, plot_name, **kwargs):\n",
    "    scaler = StandardScaler(with_mean=False)\n",
    "    X = scaler.fit_transform(X)\n",
    "    n_splits=5\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True)\n",
    "    y_prob = np.zeros((len(y),2))\n",
    "    mean_tpr = 0.0\n",
    "    mean_fpr = np.linspace(0, 1, 100)\n",
    "    all_tpr = []\n",
    "    for i, (train_index, test_index) in enumerate(kf.split(X)):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train = y[train_index]\n",
    "        clf = clf_class(**kwargs)\n",
    "        clf.fit(X_train,y_train)\n",
    "        # Predict probabilities, not classes\n",
    "        y_prob[test_index] = clf.predict_proba(X_test)\n",
    "        fpr, tpr, thresholds = roc_curve(y[test_index], y_prob[test_index, 1])\n",
    "        mean_tpr += interp(mean_fpr, fpr, tpr)\n",
    "        mean_tpr[0] = 0.0\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        plt.plot(fpr, tpr, lw=1, label='ROC fold %d (area = %0.2f)' % (i, roc_auc))\n",
    "    mean_tpr /= n_splits\n",
    "    mean_tpr[-1] = 1.0\n",
    "    mean_auc = auc(mean_fpr, mean_tpr)\n",
    "    plt.plot(mean_fpr, mean_tpr, 'k--',label='Mean ROC (area = %0.2f)' % mean_auc, lw=2)\n",
    "    \n",
    "    plt.plot([0, 1], [0, 1], '--', color=(0.6, 0.6, 0.6), label='Random', figsize=(15,15))\n",
    "    plt.xlim([-0.05, 1.05])\n",
    "    plt.ylim([-0.05, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roc(X, y, rf, 'Random_Forest')\n",
    "plot_roc(X, y, lr, 'Logistic_Regression')\n",
    "plot_roc(X, y, gdbc, 'GradientBoosting')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot Confusion Matrix\n",
    "\n",
    "def plot_conf_mat(model):\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_test)\n",
    "    cm = confusion_matrix(y_test, preds)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, preds).ravel()\n",
    "    cm = [[tp,fp],[fn,tn]]\n",
    "\n",
    "    plt.figure(figsize=(12,9))\n",
    "    ax = sns.heatmap(cm, annot=True, fmt = \"d\", cmap=\"Spectral\")\n",
    "\n",
    "    ax.set_xlabel('ACTUAL LABELS')\n",
    "    ax.set_ylabel('PREDICTED LABELS') \n",
    "    ax.set_title('Random Forest Confusion Matrix')\n",
    "    ax.xaxis.set_ticklabels(['Yes', 'No'])\n",
    "    ax.yaxis.set_ticklabels(['Yes', 'No'])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(plot_conf_mat(lr))\n",
    "print(plot_conf_mat(rf))\n",
    "print(plot_conf_mat(gdbc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
